{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    def __init__(self, text_embedding_vectors):\n",
    "        super(Embedder, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            embeddings=text_embedding_vectors, freeze=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_vec = self.embeddings(x)\n",
    "        return x_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import get_IMDb_DataLoaders_and_TEXT\n",
    "train_dl, val_dl, test_dl, TEXT = get_IMDb_DataLoaders_and_TEXT(\n",
    "    max_length=256, batch_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = Embedder(TEXT.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0]にする理由は0個目には, [0]にID列, [1]にそれぞれのベクトルの長さ(<pad>を除いたもの)が格納されているから\n",
    "x = batch.Text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   2,   14,   69,  ...,    1,    1,    1],\n",
       "         [   2,    8,   76,  ...,    1,    1,    1],\n",
       "         [   2,    8,   76,  ..., 6841,   38,    3],\n",
       "         ...,\n",
       "         [   2, 8940, 7344,  ...,  955,    0,    3],\n",
       "         [   2, 1060,    4,  ...,    8,  731,    3],\n",
       "         [   2,  572,   11,  ...,    1,    1,    1]]),\n",
       " tensor([126,  90, 256, 256, 130,  85, 256, 256, 165,  83, 159,  78, 256, 193,\n",
       "         194, 225, 256, 178, 117, 176, 206, 256, 256, 184]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = net1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 256, 300])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PositionalEncoder\n",
    "# self-attentionが位置情報を扱えない\n",
    "# 今回の実装では、文章中の単語の位置情報だけでなく、単語の分散表現それぞれの次元の位置情報も足している。\n",
    "# 本来は、単語の分散表現内のそれぞれの要素の位置までは足す必要がない\n",
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model=300, max_seq_len=256):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        pe = pe.to(device)\n",
    "        \n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** (2 * i / d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** (2 * i / d_model)))\n",
    "        \n",
    "        # 0番目に新たな次元を追加する関数\n",
    "        # ミニバッチ次元となる次元を足す\n",
    "        # こうすることでxのミニバッチサイズがいくつであろうと、この次元に沿ってブロードキャストされる\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "        \n",
    "        # 勾配を計算しないようにする\n",
    "        self.pe.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # ただ x と足すだけでも良いが、xの値が小さいので、xの値を定数倍してからpositional encodingしている\n",
    "        ret = math.sqrt(self.d_model) * x + self.pe\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 256, 300])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = Embedder(TEXT.vocab.vectors)\n",
    "net2 = PositionalEncoder()\n",
    "\n",
    "x = batch.Text[0]\n",
    "x1 = net1(x)\n",
    "x2 = net2(x1)\n",
    "\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model=300):\n",
    "        super().__init__()\n",
    "        \n",
    "        # nn.Linear は全結合層は作る関数\n",
    "        # nn.Linear(in_features, out_features, bias=True)\n",
    "        # in_features, out_features は全結合層の入力と出力の次元数\n",
    "        # 特徴量を変換するための層\n",
    "        # query, key, valueはそれぞれ同じ特徴量から作られるが、違う重みを通して特徴量を変換する\n",
    "        # self.q_linear(input)とやると、返り値が出力になる\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # 出力に用いる全結合層\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Attentionの大きさ調整の変数\n",
    "        # 別のメソッドで使うから\n",
    "        self.d_k = d_model\n",
    "        \n",
    "    # 入力は ミニバッチx１文の単語数(256)x分散表現の次元(300)\n",
    "    def forward(self, q, k, v, mask):\n",
    "        # 全結合層で特徴量を変換\n",
    "        k = self.k_linear(k)\n",
    "        q = self.q_linear(q)\n",
    "        v = self.v_linear(v)\n",
    "        \n",
    "        # torch.matmul(input, other, out=None) → Tensor\n",
    "        # inputとotherの行列\n",
    "        # k.transpose(dim0, dim1)はdim0とdim1を転置したTensorを返す\n",
    "        # 0次元はミニバッチサイズであるため1次元目と2次元目を転置する\n",
    "        # / math.sqrt(self.d_k) は matmulすると大きくなりすぎるので正規化をしている\n",
    "        # 行列の形は ミニバッチx256x300 -> ミニバッチx256x256\n",
    "        # 出力の256x256にはそれぞれの単語に対するそれぞれの単語の関連度がスカラで格納されている\n",
    "        # この時点で片方でも<pad>の場合はその関連度の値は0になる\n",
    "        weights = torch.matmul(q, k.transpose(1, 2)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # maskを計算\n",
    "        # <pad>をattentin weightsが0となるようにマスクをする\n",
    "        # softmaxするため -無限 にすることで attention weightsが0となる\n",
    "        mask = mask.unsqueeze(1)\n",
    "        # tensor.masked_fill(mask, value) maskがTrueとなるところを、valueで置き換える\n",
    "        # 今回だと<pad>の分散表現の値がすべて0であるため、計算後の値が0になっているのでそこを-1e9に置き換えている\n",
    "        weights = weights.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # torch.nn.functional.softmax(input, dim=None, _stacklevel=3, dtype=None)\n",
    "        # dim=-1は最後尾の次元を表しているので、ある単語に対してそれぞれの単語との関連度が入っているベクトルでsoftmaxをしている\n",
    "        # テンソルの形は変化なし\n",
    "        normlized_weights = F.softmax(weights, dim=-1)\n",
    "        \n",
    "        # ミニバッチを省略 256x256 ✕ 256x300 = 256x300\n",
    "        output = torch.matmul(normlized_weights, v)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        # normlized_weightsを返すのは後で確認を行うため、\n",
    "        return output, normlized_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全結合層2つとdropoutで特徴量を変換するだけの層\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.dropout(F.relu(x))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # LayerNormalization\n",
    "        # 単語ごとの、300個の要素について、平均が0,標準偏差が1になるように正規化を行う。\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.attn = Attention(d_model)\n",
    "        \n",
    "        # Attentionのあとの全結合層2つ\n",
    "        self.ff = FeedForward(d_model)\n",
    "        \n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        #######################################\n",
    "        x_normlized = self.norm_1(x)\n",
    "        # ここで q, k, vですべてx_normlizedなのがself-attention\n",
    "        output, normlized_weights = self.attn(\n",
    "        x_normlized, x_normlized, x_normlized, mask )\n",
    "        \n",
    "        x2 = x + self.dropout_1(output)\n",
    "        ########################################\n",
    "        # ここまでが一ブロック\n",
    "        # まずは、LayerNormで入力を正規化\n",
    "        # 正規化した入力でself-attention\n",
    "        # その出力と正規化していない入力xを足し合わせる 残差ネットワーク\n",
    "        # 残差ネットワーク (ResNet) ある層で求める最適な出力を学習するのではなく、層の入力を参照した残差関数を学習する\n",
    "        # つまり入力との差分のみを学習するようにする -> そのために入力をそのまま加算したものを出力とする\n",
    "        #\n",
    "        # そしてこれを2回繰り返す\n",
    "        \n",
    "        x_normlized2 = self.norm_2(x2)\n",
    "        output = x2 + self.dropout_2(self.ff(x_normlized2))\n",
    "        \n",
    "        return output, normlized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 1, 256])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1 = Embedder(TEXT.vocab.vectors)\n",
    "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
    "net3 = TransformerBlock(d_model=300)\n",
    "\n",
    "x = batch.Text[0]\n",
    "# <pad>の単語IDが1より\n",
    "input_pad = 1\n",
    "# False==0 が True になる\n",
    "input_mask = (x != input_pad)\n",
    "\n",
    "input_mask.shape\n",
    "input_mask.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 256, 300])\n"
     ]
    }
   ],
   "source": [
    "x1 = net1(x)\n",
    "x2 = net2(x1)\n",
    "x3, normlized_weights = net3(x2, input_mask)\n",
    "\n",
    "print(x3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, d_model=300, output_dim=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(d_model, output_dim)\n",
    "        \n",
    "        # torch.nn.init.normal_(tensor, mean=0.0, std=1.0)\n",
    "        # mean 正規分布の平均   std 正規分布の標準偏差\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 先頭の単語<cls>を取り出す\n",
    "        x0 = x[:, 0, :]\n",
    "        out = self.linear(x0)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassification(nn.Module):\n",
    "    def __init__(self, text_embedding_vectors, d_model=300, max_seq_len=256, output_dim=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net1 = Embedder(text_embedding_vectors)\n",
    "        self.net2 = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        self.net3_1 = TransformerBlock(d_model=d_model)\n",
    "        self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        self.net4 = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x1 = self.net1(x)\n",
    "        x2 = self.net2(x1)\n",
    "        x3_1, normlized_weights_1 = self.net3_1(x2, mask)\n",
    "        x3_2, normlized_weights_2 = self.net3_1(x3_1, mask)\n",
    "        x4 = self.net4(x3_2)\n",
    "        return x4, normlized_weights_1, normlized_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 2])\n",
      "tensor([[0.9578, 0.0422],\n",
      "        [0.9517, 0.0483],\n",
      "        [0.9567, 0.0433],\n",
      "        [0.9620, 0.0380],\n",
      "        [0.9561, 0.0439],\n",
      "        [0.9597, 0.0403],\n",
      "        [0.9579, 0.0421],\n",
      "        [0.9571, 0.0429],\n",
      "        [0.9562, 0.0438],\n",
      "        [0.9563, 0.0437],\n",
      "        [0.9537, 0.0463],\n",
      "        [0.9587, 0.0413],\n",
      "        [0.9513, 0.0487],\n",
      "        [0.9630, 0.0370],\n",
      "        [0.9562, 0.0438],\n",
      "        [0.9578, 0.0422],\n",
      "        [0.9608, 0.0392],\n",
      "        [0.9439, 0.0561],\n",
      "        [0.9501, 0.0499],\n",
      "        [0.9583, 0.0417],\n",
      "        [0.9598, 0.0402],\n",
      "        [0.9552, 0.0448],\n",
      "        [0.9431, 0.0569],\n",
      "        [0.9544, 0.0456]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "\n",
    "net = TransformerClassification(\n",
    "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256,\n",
    "    output_dim=2)\n",
    "\n",
    "x = batch.Text[0]\n",
    "input_mask = (x != input_pad)\n",
    "out, normlized_weights_1, normlized_weights_2 = net(x, input_mask)\n",
    "\n",
    "print(out.shape)\n",
    "print(F.softmax(out, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
